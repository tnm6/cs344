Exercise 8.1 of Lab 8
CS-344, Professor Vander Linden, Calvin University
Answers by Nathan Meyer (tnm6)

a.  Submit solutions to tasks 1–5.
Task 1:
    The range of median income is odd: 0.5–15.0 for both sets. Is this in
  hundreds of thousands? Or is it not a linear scale? And is 15.0 a cutoff?
    The minimum value for rooms per person is 0.0 but the minimums for
  total_rooms and population are 2.0 and 3.0 respectively. This could be due to
  rounding a very small total_rooms divided by a larger population value, but
  it seems odd in practice to have a 0.0 value for room_per_person. This is
  probably due to a simple rounding approach for decimals lower than 0.1.
    The median_house_value seems to be cut off at 500.0. Both sets have this
  maximum despite a more granular range of values for mean, etc., although the
  min values are also 15.0.
Task 2:
    The validation set has latitudes/longitudes of 36.1–42.0/-124.3–-121.4,
  while the training set has latitudes/longitudes of 32.5–41.8/-121.4–-114.3.
  So, the sets are in a sort of order based on latitude/longitude. This would
  explain why the graphs cover different "areas" of the x and y ranges.
Task 3:
    Uncommented the line which shuffles the california_housing_dataframe. This
  solves the issue of the data ordered by latitude/longitude.
Task 4:
    # 1. Create input functions.
    training_input_fn = lambda: my_input_fn(
        training_examples, training_targets['median_house_value'],
        batch_size=batch_size
    )
    predict_training_input_fn = lambda: my_input_fn(
        training_examples, training_targets['median_house_value'],
        num_epochs=1, shuffle=False
    )
    predict_validation_input_fn = lambda: my_input_fn(
        validation_examples, validation_targets['median_house_value'],
        num_epochs=1, shuffle=False
    )

    # 2. Take a break and compute predictions.
    training_predictions = linear_regressor.predict(
        input_fn=predict_training_input_fn
    )
    validation_predictions = linear_regressor.predict(
        input_fn=predict_validation_input_fn
    )

    training_predictions = np.array(
        [item['predictions'][0] for item in training_predictions]
    )
    validation_predictions = np.array(
        [item['predictions'][0] for item in validation_predictions]
    )

    # TWEAK THESE VALUES TO SEE HOW MUCH YOU CAN IMPROVE THE RMSE
    learning_rate=0.00009,
    steps=200,
    batch_size=1000
  Output:
    period 09 : 164.98 (final RMSE)
Task 5:
    california_housing_test_data = pd.read_csv("https://download.mlcc.google.com/mledu-datasets/california_housing_test.csv", sep=",")

    test_examples = preprocess_features(california_housing_test_data)
    test_targets = preprocess_targets(california_housing_test_data)

    test_predict_fn = lambda: my_input_fn(
        test_examples, test_targets['median_house_value'],
        num_epochs = 1, shuffle=False
    )

    test_predictions = linear_regressor.predict(input_fn=test_predict_fn)
    test_predictions = np.array(
        [item['predictions'][0] for item in test_predictions]
    )

    test_rmse = math.sqrt(
        metrics.mean_squared_error(test_predictions, test_targets)
    )

    print("Final RMSE: " + str(test_rmse))
  Output:
    Final RMSE: 159.807176006017

b.  Give a one-paragraph summary of what you learned about using training,
    validation, and testing datasets
  Each dataset is used for a distinct process in the model. With training, this
data is "complete" for the ML model to learn through linear regression. For
validation, the predictions are made based on the training model and are
compared to the actual results from the validation dataset for accuracy (RMSE).
Finally, after tweaking based on those first two datasets, we confirm the
performance of the model based upon the testing dataset. This way, the test set
is not "worn out" by overuse and can be a distinct, third set to double-check
the performance of the model.