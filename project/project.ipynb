{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "import sqlite3 as sql\n",
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "NUM_WORDS = 10000\n",
    "SEED = 113\n",
    "\n",
    "data = sql.connect(\"movie_lines.db\")\n",
    "cursor = data.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "cursor.execute(\"SELECT COUNT(movie_id) FROM movies\")\n",
    "count = cursor.fetchone()[0]\n",
    "\n",
    "movie_lines = []\n",
    "for i in range(count):\n",
    "    cursor.execute(\"SELECT line_text FROM lines WHERE movie_id = {}\".format(i))\n",
    "    lines = \"\"\n",
    "    lines = \" \".join([line[0] for line in cursor.fetchall()])\n",
    "    movie_lines.append(lines)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=NUM_WORDS, oov_token=\"<UNK>\")\n",
    "tokenizer.fit_on_texts(movie_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "data = np.array(tokenizer.texts_to_sequences(movie_lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"SELECT name FROM genres\")\n",
    "all_genres = np.array([genre[0] for genre in cursor.fetchall()])\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "genre_ints = label_encoder.fit_transform(all_genres)\n",
    "\n",
    "genre_dict = {}\n",
    "for i in range(len(all_genres)):\n",
    "    genre_dict[all_genres[i]] = genre_ints[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_genres = []\n",
    "for i in range(count):\n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT genres.name\n",
    "        FROM movies, genres, movie_genre_linking\n",
    "        WHERE movies.movie_id = movie_genre_linking.movie_id\n",
    "          AND genres.genre_id = movie_genre_linking.genre_id\n",
    "          AND movies.movie_id = {}\n",
    "        \"\"\".format(i))\n",
    "    genres = [genre[0] for genre in cursor.fetchall()]\n",
    "    movie_genres.append(genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(movie_genres_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_genres_int = []\n",
    "for entry in movie_genres:\n",
    "    int_encoded = []\n",
    "    for genre in entry:\n",
    "        int_encoded.append(genre_dict[genre])\n",
    "    movie_genres_int.append(int_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomize and Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on keras.datasets.imdb implementation of shuffling\n",
    "np.random.seed(SEED)\n",
    "indices = np.arange(len(data))\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = labels[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data[:462]\n",
    "train_labels = labels[:462]\n",
    "test_data = data[462:]\n",
    "test_labels = labels[462:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Hot Encode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Network (*VERY* much a prototype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/3.5-classifying-movie-reviews.ipynb\n",
    "def vectorize_sequences(sequences, dimension=NUM_WORDS):\n",
    "    # Create an all-zero matrix of shape (len(sequences), dimension)\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.  # set specific indices of results[i] to 1s\n",
    "    return results\n",
    "\n",
    "x_train = vectorize_sequences(train_data)\n",
    "x_test = vectorize_sequences(test_data)\n",
    "\n",
    "y_train = vectorize_sequences(train_labels, dimension=len(all_genres))\n",
    "y_test = vectorize_sequences(test_labels, dimension=len(all_genres))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(462, 10000)\n(462, 24)\n"
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:From /Users/nathan/CS/344/env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n\nWARNING:tensorflow:From /Users/nathan/CS/344/env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n\nWARNING:tensorflow:From /Users/nathan/CS/344/env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n\n"
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(NUM_WORDS,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(y_train.shape[1], activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:From /Users/nathan/CS/344/env/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n\nWARNING:tensorflow:From /Users/nathan/CS/344/env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n\nWARNING:tensorflow:From /Users/nathan/CS/344/env/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.where in 2.0, which has the same broadcast rule as np.where\n"
    }
   ],
   "source": [
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/10\n462/462 [==============================] - 0s 161us/step - loss: 0.0330 - acc: 0.9886\nEpoch 2/10\n462/462 [==============================] - 0s 131us/step - loss: 0.0276 - acc: 0.9899\nEpoch 3/10\n462/462 [==============================] - 0s 136us/step - loss: 0.0268 - acc: 0.9901\nEpoch 4/10\n462/462 [==============================] - 0s 140us/step - loss: 0.0270 - acc: 0.9906\nEpoch 5/10\n462/462 [==============================] - 0s 133us/step - loss: 0.0238 - acc: 0.9915\nEpoch 6/10\n462/462 [==============================] - 0s 150us/step - loss: 0.0241 - acc: 0.9913\nEpoch 7/10\n462/462 [==============================] - 0s 136us/step - loss: 0.0233 - acc: 0.9929\nEpoch 8/10\n462/462 [==============================] - 0s 133us/step - loss: 0.0216 - acc: 0.9922\nEpoch 9/10\n462/462 [==============================] - 0s 137us/step - loss: 0.0206 - acc: 0.9926\nEpoch 10/10\n462/462 [==============================] - 0s 136us/step - loss: 0.0197 - acc: 0.9933\n155/155 [==============================] - 0s 45us/step\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[0.516097576964286, 0.9002688157942987]"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=10, batch_size=16)\n",
    "\n",
    "predictions = model.predict(x_test)\n",
    "results = model.evaluate(x_test, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to proceed?\n",
    "\n",
    "1. One-hot encode all of the genre permutations (i.e. ['action', 'drama', 'crime'] indexed and encoded to one value, etc.)\n",
    "2. Rework the data to utilize embeddings instead\n",
    "3. Eliminate all but the first genre entry for each movie\n",
    "  - **Problem**: Genres sorted alphabetically, and a few movies have no genres (empty lists)\n",
    "4. Some other way I have not considered?\n",
    "  - Can densely-connected neural networks predict multiple labels for one entry (i.e. movie)?\n",
    "  - [This article](https://medium.com/@vijayabhaskar96/multi-label-image-classification-tutorial-with-keras-imagedatagenerator-cd541f8eaf24) supposes using Keras functions instead of the Sequential Keras model\n",
    "  - [This answer](https://stackoverflow.com/a/44165755) seems to be a more intuitive option where predictions are given thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Other Next Steps\n",
    "\n",
    "- Consolidate Cornell data generation into a cornell.py module"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37664bitenvvenv964bff84c05a45e6adc7a8f890209e2c",
   "display_name": "Python 3.7.6 64-bit ('env': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}