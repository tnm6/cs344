Exercise 11.1 of Lab 11
CS-344, Professor Vander Linden, Calvin University
Answers by Nathan Meyer (tnm6)

a.  Task 1: Is a linear model ever preferable to a deep NN model?
  A linear model may require less data, and less time to train. Some problems
might only need the relative simplicity of a linear model, so it would not make
sense to add the complexity and intensive data/performance requirements of a
deep NN. However, where accuracy is of the utmost priority, a NN would be the
ideal choice.

b.  Task 2: Does the NN model do better than the linear model?
  Its accuracy is notably higher, 84% vs 78.34%, and the average loss is notably
lower, 0.32 vs 0.45, for the test set, so yes, it performs better than the
linear model.

c.  Task 3: Do embeddings do much good for sentiment analysis tasks?
  Not really in this case. Without embeddings, the deep NN had an accuracy of
84% while, with an embedding layer added, had an accuracy of 78% on the test
set. The average loss, AUC, etc. are also worse. Interestingly though, they are
quite comparable to the linear model.

d.  Tasks 4â€“5: Name two words that have similar embeddings and explain why that
    makes sense.
  'Hilarious' and 'comedy' have similar embeddings. This makes sense, since a
film with associated with comedy (either by genre or with comedic elements)
traits would, ideally, have hilarious elements (what a weirdly technical way to
talk about it...). They are also two words in the larger group of similarly
embedded words that are positive, such as 'entertaining.'

e.  Task 6: Report your best hyper-parameters and their resulting performance.
  The Colaboratory notebook had several bugs where the accuracy bottomed out at
0.5, but after a few runs, these are the settings that seemed to work a little
better (changed learning rate to 0.02):

  my_optimizer = tf.train.AdagradOptimizer(learning_rate=0.2)
  my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)

  classifier = tf.estimator.DNNClassifier(
    feature_columns=feature_columns,
    hidden_units=[10,10],
    optimizer=my_optimizer
  )

  accuracy 0.84632